---
title: 'AI-расширения VS Code: nothing compares to C…'
description: 'Ради исследовательского интереса попробовал бесплатные альтернативы <a href="/ru/blog/2024/cursor">Cursor</a>. К сожалению, результаты эксперимента неутешительны: ничего и близко не стояло с редактором Anysphere. Если вы не можете платить за него по $20 в месяц лучшее, на что можете рассчитывать, &mdash; это &laquo;нативные&raquo; приложения ChatGPT и Claude. Они крутые, но не могут действовать, как ИИ-агенты и постоянно теряют контекст.'
image: img/blog/2024/12-28/vscode.png
categories: Разработка
date: 2024-12-28
---

Из расширений более-менее полезны только Copilot и Codeium — для правки ошибок Eslint и TypeScript.

Остальные мало в чем помогают и проигрывают, как Cursor'у, так и самостоятельным приложениям ChatGPT и Claude.

[Про Windsurf я уже писал](/ru/blog/2024/windsurf) — хорошо, дешевле, но не Cursor.

## «Нативные» приложения ChatGPT и Claude

[Десктопные версии Claude](https://claude.ai/download) — по-сути обёртка для веб-приложения самой умной модели для программирования. Интерфейс, к сожалению, столь же сырой, как и в браузере.

[ChatGPT](https://help.openai.com/en/articles/10119604-work-with-apps-on-macos) удобнее, но, насколько понимаю, выпущен пока только под macOS. Далее следует его «прямая речь».

> Для помощи в кодировании убедитесь, что приложение запущено, затем в строке чата ChatGPT нажмите кнопку «Work With Apps» и выберите совместимое приложение (см. ниже). При отправке сообщения ChatGPT будет учитывать содержимое выбранных приложений, улучшая качество ответов.
>
> Функция поддерживает текстовые редакторы (Apple Notes, Notion, TextEdit, Quip), кодовые редакторы (Xcode, VS Code, Jetbrains и другие) и терминалы (Terminal, iTerm, Warp, Prompt). При подготовке ответа ChatGPT учитывает полный контент открытых окон редакторов или последние 200 строк терминала, с учетом выделенного текста для более точного контекста.
>
> Для вызова модального окна с мини-приложением в VS Code надо нажать `⌥⇧1`. Выделите фрагмент кода и затем вводите промт. Чтобы работать с несколькими файлами одновременно, открывайте их в разделенных редакторах.
>
> Для работы с большинством приложений требуется разрешение на доступ к API доступности macOS, которое можно настроить в системных настройках. Для VS Code необходимо установить специальное расширение. Вы можете управлять совместимыми приложениями и их настройками в разделе ChatGPT: Settings > Work with Apps > Manage Apps.

## Copilot

Встроенный ИИ-помощник VS Code разочаровал. Удобный интерфейс, Claude «под капотом». Непонятно почему, но ответы гораздо хуже, чем у «нативного» приложения Anthropic.

### Возможности бесплатной версии

- **Автодополнение кода:** до 2000 автодополнений в месяц (примерно 80 в день).
- **Чат:** до 50 запросов в чате в месяц.
- **Доступ к моделям:** включает модели GPT-4o от OpenAI и Claude 3.5 Sonnet от Anthropic.

### Установка и активация

1. Установите расширение GitHub Copilot в Visual Studio Code.
2. Авторизуйтесь через учетную запись GitHub, имеющую активную подписку Copilot.
3. Проверьте настройки `github.copilot.advanced` в `settings.json` для тонкой настройки поведения:

   ```json
   {
     "github.copilot.advanced": {
       "inlineSuggest.enable": true,
       "autoComplete.enable": true,
       "suggestions.showOnDemand": true
     }
   }
   ```

### Основные функции

- **Генерация кода на основе комментариев**. Напишите комментарий с описанием задачи. Пример:

    ```typescript
    // Функция для вычисления факториала числа
    ```

    Copilot предложит соответствующую реализацию.

- **Автодополнение**. Начните писать код, и Copilot будет предлагать продолжение. Пример:

    ```typescript
    const fetchData = async (url: string) => {
    ```

    Copilot автоматически добавит шаблон асинхронной функции с обработкой ответа.

- **Оптимизация и пояснение существующего кода**. Выделите фрагмент кода, щелкните правой кнопкой мыши и выберите:

  - "Explain code"
  - "Refactor code"

### Планирование кода и рабочий процесс

1. **Анализ требований**. Убедитесь, что Copilot понимает контекст. Предоставьте точные и понятные комментарии.
2. **Генерация псевдокода**. Напишите шаги на естественном языке или в псевдокоде, чтобы Copilot мог предложить наиболее точное решение.
3. **Подтверждение предложений**. Пересматривайте предложения Copilot и принимайте их с помощью `Tab`, либо изменяйте вручную для соответствия требованиям.

### Советы

1. **Создание модульного кода**. Используйте Copilot для генерации повторяемых структур, таких как интерфейсы, функции-обёртки и обработчики ошибок.
2. **Валидация пользовательского ввода**. Обеспечьте высокую безопасность, следуя рекомендациям в секции `<SECURITY_REVIEW>`.
3. **Тестирование и отладка**. Генерируйте тесты с помощью Copilot, предоставляя комментарии:

    ```typescript
    // Напиши тест для функции fetchData с использованием Jest
    ```

#### TypeScript

- Всегда включайте строгую типизацию, чтобы Copilot предлагал корректный код.
- Используйте интерфейсы вместо типов для гибкости:

    ```typescript
    interface User {
      id: number;
      name: string;
      email: string;
    }
    ```

#### React

- Укажите, что вы используете функциональные компоненты, чтобы Copilot предлагал корректный JSX:

  ```typescript
  // Создай компонент React, который отображает список пользователей
  ```

#### Оптимизация работы

1. **Используйте контекст проекта**. Откройте все связанные файлы, чтобы Copilot мог анализировать больше данных.

2. **Четкие комментарии**. Используйте комментарии на естественном языке для повышения точности генерации.

3. **Используйте Copilot для рутинных задач**. Например, создания вспомогательных функций, обработки ошибок или написания тестов.

### Ограничения

1. **Контекстный лимит**. Copilot анализирует ограниченное количество строк до и после курсора. Убедитесь, что ключевой контекст видим.

2. **Ручная проверка**. Всегда пересматривайте предложения Copilot, чтобы избежать неэффективного или небезопасного кода.

3. **Лицензирование**. Убедитесь, что использование Copilot соответствует вашим требованиям к лицензированию кода.

## Codeium

**2 млн** скачиваний; 1403 оценки; средняя — **5**.

Базовая функциональность бесплатна. Неплох для исправления ошибок Eslint, Stylelint, а также для написания JDoc'ов. Автозаполнение неудачное.

В бесплатной версии доступна только переделанная  Llama (Codeium называет ее Basic Model). Подключить ChatGPT или Claude с помощью API-ключей нельзя — они поставляются только «вшитыми» в платную версию.

## CodeGPT

**1,5 млн** скачиваний; 227 оценок; средняя — **4**.

Может работать на Ollam'е и на ChatGPT (надо ввести API-ключ) но количество обращений ограничено 8 в день.

- После установки введите ваш API-ключ OpenAI в настройках расширения.
- Используйте командную панель для доступа к функциям CodeGPT.
- Выделите код и выберите соответствующую команду для получения помощи от AI.

## Cline

**208 тыс.** скачиваний; 84 оценки; средняя — **5**.

Лучше всего работает с Claude, о чем постоянно напоминает. Но Claude платный — для использования надо закупать токены по схеме Pay-as-you-go.

Однако можно использовать бесплатную Ollam'у. Которая, впрочем, с большими задачами — типа, «перепиши боковую панель @index.pug на React, используй компоненты @src» — не справляется.

### Инструкции, подготовленные ChatGPT

1. **Установите Ollama:**

   Скачайте и установите Ollama, инструмент для локального запуска крупных языковых моделей (LLM), с [официального сайта](https://ollama.com/).

2. **Установите расширение Cline:**

   - Откройте Visual Studio Code.
   - Перейдите в раздел расширений, нажав на значок Extensions в боковой панели.
   - В строке поиска введите "Cline" и установите соответствующее расширение.

3. **Настройте Cline для использования Ollama:**

   - После установки расширения Cline перейдите в его настройки.
   - В разделе настроек выберите Ollama в качестве провайдера API.
   - Укажите модель, которую вы хотите использовать, например, `llama3.2`.
   - Сохраните изменения, нажав кнопку "Done".

   Выбор модели.

   - **CodeLlama** — для кодирования. Если ваша основная задача связана с программированием, будет лучшим выбором благодаря своей специализации на коде.
   - **Llama 3.1** — для сложных аналитических задач. Если вам нужно обрабатывать большие объемы данных или выполнять сложные вычисления.
   - **Llama 3.2** — для мультимодальных приложений. Если вы планируете использовать текстовые и визуальные данные одновременно или работать на мобильных устройствах, то будет наиболее подходящей моделью.

4. **Загрузите выбранную модель в Ollama:**

   - Откройте терминал на вашем компьютере.
   - Введите команду для загрузки модели, например:

   ```sh
   ollama pull llama3.2

- Дождитесь завершения загрузки модели.

5. **Запустите Ollama:**

   Убедитесь, что Ollama запущен и работает в фоновом режиме. Даже если у вас установлено приложение Ollama с графическим интерфейсом, рекомендуется запускать серверную часть Ollama через терминал для обеспечения стабильного соединения.

   ```sh
   ollama serve
   ```

   ☝️🧐 **Команда `ollama run <model_name>` для работы с Cline не подходит.** А то, что при запуске сервере непонятно, какая модель используется сейчас неважно. Модель выбирается динамически согласно настройкам в Cline. В примере — это самая подходящая для кодирования модель Codellama.

   ![Настройки Cline](https://i.imgur.com/Up25dIL.png)

6. **Используйте Cline с моделью Ollama:**

   Теперь вы можете вводить запросы в Cline, и они будут обрабатываться с использованием выбранной модели Ollama.

## Continue.dev

**505 тыс.** скачиваний; 65 оценки; средняя — **4,5**.

### Инструкции, подготовленные ChatGPT

1. **Ollama**. Скачайте и установите [Ollama](https://ollama.com), который позволяет запускать модели ИИ локально.

2. **Модель ИИ**. Выберите модель ИИ, соответствующую вашим потребностям, например, **Llama 3** или **Code Llama**. Вы можете загрузить эти модели с помощью Ollama, используя следующие команды:

   ```sh
   ollama pull codellama
   ollama pull starcoder2:3b
   ```

3. Получите API ключ. [На сайте Mistral AI, в разделе Codestral](https://console.mistral.ai/codestral) создайте API ключ.

4. **Установите расширение Continue**.

   - Откройте VS Code.
   - Перейдите в раздел расширений, нажав на иконку расширений в боковой панели или нажав `Ctrl+Shift+X`.
   - Найдите "Continue" и нажмите кнопку `Установить` для расширения Continue .

5. **Настройте Continue.dev**.

   - После установки в боковой панели появится иконка Continue. Нажмите на нее, чтобы открыть интерфейс Continue.
   - Откройте настройки, нажав на значок шестеренки в правом нижнем углу окна Continue.
   - Добавьте конфигурацию вашей модели ИИ в файл `~/.continue/config.json`. Вот пример конфигурации для использования Code Llama:

     ```json
     {
       "models": [
         {
           "title": "CodeLlama",
           "provider": "ollama",
           "model": "codellama",
           "apiBase": "http://localhost:11434/"
         }
       ],
       "tabAutocompleteModel": {
         "title": "Codestral",
         "provider": "mistral",
         "model": "codestral-latest",
         "apiKey": "[API-KEY]"
       }
     }
     ```

   И для Codestral / Mistral API:

   ```json
      "tabAutocompleteModel": {
        "title": "Starcoder2 3b",
        "provider": "ollama",
        "model": "starcoder2:3b",
        "apiBase": "http://localhost:11434/"
      }
   ```

6. **Запустите ваши модели\***. Убедитесь, что Ollama запущен и выбранные вами модели активны. Возможно, вам потребуется запустить сервер для ваших моделей, если это необходимо.

7. **Использование Continue.dev**.
   - Как только все настроено, вы можете начать кодировать! Используйте функции автозаполнения, объяснения кода и рефакторинга прямо в VS Code.
   - Выделяйте участки кода и используйте сочетания клавиш для взаимодействия с возможностями ИИ Continue.
